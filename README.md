# Pythonå¤§ä½œä¸šï¼šYOLO + UNet/DeepLabV3+ + SAM ç»¼åˆåˆ†å‰²å®éªŒ

> æœ¬ä»“åº“æä¾›å®Œæ•´çš„è®¡ç®—æœºè§†è§‰åˆ†å‰²å®éªŒæµç¨‹ï¼Œé›†æˆ YOLO ç›®æ ‡æ£€æµ‹ã€UNet/DeepLab è¯­ä¹‰åˆ†å‰²ã€SAM å¾®è°ƒä¸æ¨ç†ã€‚  
> æ”¯æŒå¤šæ¨¡å‹æ€§èƒ½å¯¹æ¯”ã€ç»Ÿä¸€å¯è§†åŒ–ã€å…¨é¢æŒ‡æ ‡è¯„ä¼°ã€‚

## ğŸ“ 1. é¡¹ç›®ç›®å½•ç»“æ„
```text
Pythonå¤§ä½œä¸š/
â”œâ”€ dataset_seg/         # UNet/DeepLab/SAM æ•°æ®é›†ï¼ˆè¯­ä¹‰åˆ†å‰²ï¼‰
â”‚  â”œâ”€ images/{train,valid,test}/
â”‚  â””â”€ masks/{train,valid,test}/
â”‚
â”œâ”€ dataset_yolo/        # YOLO æ•°æ®é›†ï¼ˆYOLO æ ‡æ³¨æ ¼å¼ï¼‰
â”‚  â”œâ”€ images/{train,val,test}/
â”‚  â””â”€ labels/{train,val,test}/
â”‚
â”œâ”€ runs/                # SAM/YOLO è®­ç»ƒè¾“å‡º
â”‚
â”œâ”€ results/         # æ‰€æœ‰æ¨¡å‹æ¨ªå‘æ‹¼å›¾å¯è§†åŒ–
|
â”œâ”€ runs/            # YOLOv11é¢„æµ‹è¾“å‡ºç»“æœ
â”‚
â”œâ”€ tools/               # æœ¬ä»“åº“æ ¸å¿ƒä»£ç 
â”‚  â”œâ”€ ft_sam.py         # SAM å¾®è°ƒ
â”‚  â”œâ”€ infer_sam.py      # SAM æ¨ç†
â”‚  â”œâ”€ infer_unet.py     # UNet/DeepLab æ¨ç†
â”‚  â”œâ”€ train_unet.py     # UNet/AttUNet/UNet++ è®­ç»ƒ
â”‚  â”œâ”€ train_deeplabv3+.py
â”‚  â”œâ”€ train_yolo.py
â”‚  â”œâ”€ predict_yolo.py
â”‚  â”œâ”€ show_diff.py      # å¤šæ¨¡å‹å¯¹æ¯”å¯è§†åŒ–
â”‚  â””â”€ trans.py          # æ•°æ®è½¬æ¢å·¥å…·
â”‚
â”œâ”€ Unet/                # â˜… éœ€è¦æ‰‹åŠ¨å…‹éš† Awesome-UNet åˆ°æ­¤
â”‚  â””â”€ Awesome-U-Net/
â”‚     â”œâ”€ models/unet.py
â”‚     â”œâ”€ models/attunet.py
â”‚     â””â”€ models/unetpp.py
â”‚
â”œâ”€ segment-anything/    # â˜… éœ€è¦æ‰‹åŠ¨å…‹éš† SAM
â”‚  â”œâ”€ sam_vit_b_01ec64.pth
â”‚  â””â”€ ...
â”‚
â””â”€ ultralytics/         # YOLO æºç ï¼Œä¹Ÿå¯ pip å®‰è£…

```

---

## âš™ï¸ 2. ç¯å¢ƒå®‰è£…ï¼ˆå¿…è¯»ï¼‰

### 2.1 Python ä¾èµ–åŒ…

å»ºè®®ä½¿ç”¨ Python 3.8+ ç¯å¢ƒï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…æ‰€éœ€ä¾èµ–ï¼š
```bash
# åŸºç¡€ç§‘å­¦è®¡ç®—åº“
pip install numpy opencv-python tqdm matplotlib pyyaml

# æ·±åº¦å­¦ä¹ æ¡†æ¶
pip install torch torchvision torchaudio

# åˆ†å‰²æ¨¡å‹åº“
pip install segmentation-models-pytorch

# YOLO æ¡†æ¶
pip install ultralytics

# COCO è¯„ä¼°å·¥å…·
pip install pycocotools
```

**æç¤º**ï¼šå¦‚é‡åˆ° PyTorch å®‰è£…é—®é¢˜ï¼Œè¯·è®¿é—® [PyTorch å®˜ç½‘](https://pytorch.org/) æ ¹æ®æ‚¨çš„ CUDA ç‰ˆæœ¬é€‰æ‹©åˆé€‚çš„å®‰è£…å‘½ä»¤ã€‚

---

## ğŸ“¦ 3. æ‰‹åŠ¨å…‹éš†å¤–éƒ¨ä¾èµ–ï¼ˆæœ¬ä»“åº“æœªåŒ…å«ï¼‰

### 3.1 Segment Anything (SAM)

**å…‹éš†ä»“åº“ï¼š**
```bash
git clone https://github.com/facebookresearch/segment-anything.git
```

**ä¸‹è½½é¢„è®­ç»ƒæƒé‡ï¼š**

è¯·ä» [SAM å®˜æ–¹ä»“åº“](https://github.com/facebookresearch/segment-anything#model-checkpoints) ä¸‹è½½æƒé‡æ–‡ä»¶ï¼ˆæ¨è ViT-Bï¼‰ï¼š
```bash
# å°†ä¸‹è½½çš„æƒé‡æ”¾ç½®åœ¨æ­¤è·¯å¾„
segment-anything/sam_vit_b_01ec64.pth
```

### 3.2 Awesome-UNet

**å…‹éš† Pytorch-UNet ä»“åº“ï¼š**
```bash
mkdir Unet
cd Unet
git clone https://github.com/milesial/Pytorch-UNet.git Awesome-U-Net
```

**ç¡®è®¤æ–‡ä»¶ç»“æ„ï¼š**
```bash
Unet/Awesome-U-Net/
â”œâ”€ models/unet.py       # æ ‡å‡† UNet
â”œâ”€ models/attunet.py    # Attention UNet
â””â”€ models/unetpp.py     # UNet++
```

### 3.3 YOLO (Ultralytics)

**æœ€ç®€å•æ–¹å¼ï¼ˆæ¨èï¼‰ï¼š**
```bash
pip install ultralytics
```

**æˆ–æ‰‹åŠ¨å…‹éš†ï¼ˆå¯é€‰ï¼‰ï¼š**
```bash
git clone https://github.com/ultralytics/ultralytics.git
```

---

## ğŸ“Š 4. æ•°æ®æ ¼å¼è¯´æ˜

### 4.1 è¯­ä¹‰åˆ†å‰²æ•°æ®é›†ï¼ˆUNet/DeepLab/SAMï¼‰

**ç›®å½•ç»“æ„ï¼š**
```bash
dataset_seg/
â”œâ”€ images/
â”‚  â”œâ”€ train/xxx.jpg
â”‚  â”œâ”€ valid/xxx.jpg
â”‚  â””â”€ test/xxx.jpg
â””â”€ masks/
   â”œâ”€ train/xxx.png    # å•é€šé“ç°åº¦å›¾ï¼Œå‰æ™¯åƒç´ å€¼ > 0
   â”œâ”€ valid/xxx.png
   â””â”€ test/xxx.png
```

**æ•°æ®é›†ä¸‹è½½ï¼š**

- **æ¨èæ•°æ®é›†**ï¼š[flower_segmentationV2 Dataset by MOD05GEN25HUGO](https://universe.roboflow.com/mod05gen25hugo/flower_segmentationv2)
- ä¸‹è½½åè§£å‹è‡³ `dataset_seg/` ç›®å½•

**æ•°æ®è¦æ±‚ï¼š**

- å›¾åƒæ ¼å¼ï¼š`.jpg` / `.png`
- æ©ç æ ¼å¼ï¼šå•é€šé“ PNGï¼ŒèƒŒæ™¯ä¸º 0ï¼Œå‰æ™¯ä¸º 1 æˆ– 255
- å›¾åƒä¸æ©ç æ–‡ä»¶åå¿…é¡»ä¸€ä¸€å¯¹åº”

### 4.2 YOLO æ•°æ®é›†

**ç›®å½•ç»“æ„ï¼š**
```bash
dataset_yolo/
â”œâ”€ images/
â”‚  â”œâ”€ train/
â”‚  â”œâ”€ val/
â”‚  â””â”€ test/
â””â”€ labels/
   â”œâ”€ train/xxx.txt    # YOLO æ ¼å¼æ ‡æ³¨
   â”œâ”€ val/xxx.txt
   â””â”€ test/xxx.txt
```

**æ ‡æ³¨æ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªç›®æ ‡ï¼‰ï¼š**
```text
class_id center_x center_y width height
```

- æ‰€æœ‰åæ ‡å€¼å½’ä¸€åŒ–åˆ° [0, 1]
- ç¤ºä¾‹ï¼š`0 0.5 0.5 0.3 0.4`

---

## ğŸš€ 5. å¿«é€Ÿå¼€å§‹

### 5.1 è®­ç»ƒ UNet ç³»åˆ—æ¨¡å‹
```bash
python tools/train_unet.py \
    --model unet \              # å¯é€‰: unet, attunet, unetpp
    --img_size 512 \
    --batch_size 4 \
    --epochs 50 \
    --lr 0.001 \
    --data_dir dataset_seg
```

### 5.2 è®­ç»ƒ DeepLabV3+
```bash
python tools/train_deeplabv3+.py \
    --backbone resnet50 \
    --img_size 512 \
    --batch_size 8 \
    --epochs 50
```

### 5.3 å¾®è°ƒ SAM
```bash
python tools/ft_sam.py \
    --model_type vit_b \
    --checkpoint segment-anything/sam_vit_b_01ec64.pth \
    --train_dir dataset_seg/images/train \
    --mask_dir dataset_seg/masks/train \
    --epochs 10 \
    --batch_size 2
```

### 5.4 è®­ç»ƒ YOLO
```bash
python tools/train_yolo.py \
    --model yolov8n.pt \
    --data dataset_yolo/data.yaml \
    --epochs 100 \
    --imgsz 640
```

---

## ğŸ” 6. æ¨¡å‹æ¨ç†

### 6.1 UNet/DeepLab æ¨ç†
```bash
python tools/infer_unet.py \
    --model_path runs/unet/best.pth \
    --img_dir dataset_seg/images/test \
    --output_dir results/unet
```

### 6.2 SAM æ¨ç†
```bash
python tools/infer_sam.py \
    --checkpoint runs/sam/finetuned_sam.pth \
    --img_dir dataset_seg/images/test \
    --output_dir results/sam
```

### 6.3 YOLO æ¨ç†
```bash
python tools/predict_yolo.py \
    --weights runs/yolo/best.pt \
    --source dataset_yolo/images/test \
    --save_dir results/yolo
```

---

## ğŸ“ˆ 7. æ¨¡å‹å¯¹æ¯”ä¸å¯è§†åŒ–

**ç”Ÿæˆå¤šæ¨¡å‹å¯¹æ¯”å›¾ï¼š**
```bash
python tools/show_diff.py \
    --original dataset_seg/images/test \
    --gt dataset_seg/masks/test \
    --pred_unet results/unet \
    --pred_sam results/sam \
    --pred_deeplab results/deeplab \
    --output compare_all
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
- æ¨ªå‘æ‹¼æ¥ï¼šåŸå›¾ | GT | UNet | SAM | DeepLab
- è‡ªåŠ¨è®¡ç®—å„æ¨¡å‹ IoU/Dice æŒ‡æ ‡å¹¶æ ‡æ³¨åœ¨å›¾åƒä¸Š

---

## â“ 8. å¸¸è§é—®é¢˜ï¼ˆFAQï¼‰

### Q1: AttUNet æ¨ç†æ•ˆæœå¾ˆå·®ï¼Ÿ

**A: 90% çš„æƒ…å†µæ˜¯ä»¥ä¸‹åŸå› å¯¼è‡´ï¼š**

1. **å›¾åƒå°ºå¯¸ä¸ä¸€è‡´**  
   è®­ç»ƒæ—¶ä½¿ç”¨ `--img_size 512`ï¼Œæ¨ç†æ—¶å´ç”¨äº†å…¶ä»–å°ºå¯¸ â†’ åŠ¡å¿…ä¿æŒä¸€è‡´

2. **æ¨¡å‹è·¯å¾„é”™è¯¯**  
   æ¨ç†åŠ è½½çš„æ˜¯ `.../unet/best.pth` è€Œé `.../attunet/best.pth`

3. **æ©ç å€¼èŒƒå›´ä¸åŒ¹é…**  
   è®­ç»ƒæ—¶ mask å†™æˆ 255ï¼Œæ¨ç† resize åé˜ˆå€¼åˆ¤æ–­é”™è¯¯ â†’ ç»Ÿä¸€ä½¿ç”¨ 0/1 æˆ– 0/255

4. **æ•°æ®å¢å¼ºä¸ä¸€è‡´**  
   è®­ç»ƒæ—¶ä½¿ç”¨éšæœºè£å‰ªï¼Œæ¨ç†æ—¶æœªåšç›¸åº”çš„ padding å¤„ç†

**è§£å†³æ–¹æ¡ˆ**ï¼šæ£€æŸ¥è®­ç»ƒé…ç½®æ–‡ä»¶ï¼Œç¡®ä¿æ¨ç†æ—¶ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å‚æ•°ã€‚

---

### Q2: ä¸ºä»€ä¹ˆ SAM æ¨ç†é€Ÿåº¦æ…¢ï¼Ÿ

**A: åŸå› åˆ†æï¼š**

- SAM é‡‡ç”¨ **Vision Transformer (ViT)** ä½œä¸ºå›¾åƒç¼–ç å™¨ï¼Œè®¡ç®—é‡å·¨å¤§
- ViT-B æ¨¡å‹å‚æ•°é‡çº¦ 90Mï¼Œå•å¼ å›¾åƒç¼–ç è€—æ—¶è¾ƒé•¿

**ä¼˜åŒ–å»ºè®®ï¼š**

1. **ä½¿ç”¨ GPU**ï¼šç¡®ä¿ CUDA å¯ç”¨ï¼Œé¿å… CPU æ¨ç†
2. **é™ä½æ‰¹æ¬¡å¤§å°**ï¼šViT-B å»ºè®®ä½¿ç”¨ `batch_size=1`
3. **ä½¿ç”¨æ›´å°æ¨¡å‹**ï¼šå°è¯• ViT-Tiny æˆ– MobileSAM
4. **å›¾åƒé¢„å¤„ç†**ï¼šé€‚å½“é™ä½è¾“å…¥åˆ†è¾¨ç‡ï¼ˆå¦‚ 1024 â†’ 512ï¼‰

---

### Q3: å¦‚ä½•è½¬æ¢æ•°æ®é›†æ ¼å¼ï¼Ÿ

**A: ä½¿ç”¨å†…ç½®è½¬æ¢å·¥å…·ï¼š**
```bash
python tools/trans.py \
    --input_format coco \        # è¾“å…¥æ ¼å¼: coco/voc/yolo
    --output_format seg \        # è¾“å‡ºæ ¼å¼: seg/yolo
    --input_dir raw_dataset \
    --output_dir dataset_seg
```

æ”¯æŒçš„æ ¼å¼è½¬æ¢ï¼š
- COCO â†’ è¯­ä¹‰åˆ†å‰²
- VOC â†’ YOLO
- YOLO â†’ è¯­ä¹‰åˆ†å‰²

---

### Q4: è®­ç»ƒæ—¶æ˜¾å­˜ä¸è¶³ï¼Ÿ

**A: ä¼˜åŒ–ç­–ç•¥ï¼š**

1. **å‡å°æ‰¹æ¬¡å¤§å°**ï¼š`--batch_size 2` æˆ– `--batch_size 1`
2. **é™ä½å›¾åƒåˆ†è¾¨ç‡**ï¼š`--img_size 256` æˆ– `--img_size 384`
3. **ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ**ï¼šæ·»åŠ  `--amp` å‚æ•°
4. **ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯**ï¼š`--accumulate 4`ï¼ˆæ¯4æ­¥æ›´æ–°ä¸€æ¬¡ï¼‰
5. **å†»ç»“éƒ¨åˆ†å±‚**ï¼šä»…è®­ç»ƒè§£ç å™¨éƒ¨åˆ†

---

## ğŸ› ï¸ 9. é«˜çº§åŠŸèƒ½

### 9.1 æ•°æ®å¢å¼ºé…ç½®

ä¿®æ”¹ `tools/train_unet.py` ä¸­çš„ `get_transforms()` å‡½æ•°ï¼š
```python
import albumentations as A

transform = A.Compose([
    A.RandomRotate90(),
    A.Flip(),
    A.ColorJitter(brightness=0.2, contrast=0.2),
    A.GaussNoise(p=0.2),
    A.Resize(img_size, img_size),
])
```

### 9.2 å­¦ä¹ ç‡è°ƒåº¦

æ”¯æŒçš„è°ƒåº¦å™¨ï¼š
- **StepLR**ï¼šæ¯ N ä¸ª epoch è¡°å‡
- **CosineAnnealingLR**ï¼šä½™å¼¦é€€ç«
- **ReduceLROnPlateau**ï¼šéªŒè¯é›†æŒ‡æ ‡åœæ»æ—¶è¡°å‡

### 9.3 æ—©åœæœºåˆ¶
```bash
python tools/train_unet.py \
    --early_stopping \
    --patience 10        # éªŒè¯é›†æŒ‡æ ‡ 10 ä¸ª epoch ä¸æå‡åˆ™åœæ­¢
```

---

## ğŸ“„ 10. è®¸å¯ & è‡´è°¢

### å¼€æºè®¸å¯

æœ¬é¡¹ç›®é‡‡ç”¨ **MIT License** å¼€æºåè®®ã€‚

### è‡´è°¢

æœ¬é¡¹ç›®ä¾èµ–ä»¥ä¸‹ä¼˜ç§€å¼€æºé¡¹ç›®ï¼š

- **[Segment Anything](https://github.com/facebookresearch/segment-anything)** - Meta AI Research
- **[Ultralytics YOLO](https://github.com/ultralytics/ultralytics)** - Ultralytics
- **[Pytorch-UNet](https://github.com/milesial/Pytorch-UNet)** - Milesial
- **[Segmentation Models PyTorch](https://github.com/qubvel/segmentation_models.pytorch)** - Pavel Yakubovskiy

ç‰¹åˆ«æ„Ÿè°¢æ‰€æœ‰ä¸ºè®¡ç®—æœºè§†è§‰å¼€æºç¤¾åŒºåšå‡ºè´¡çŒ®çš„å¼€å‘è€…ï¼
