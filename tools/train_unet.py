import os
import time
import argparse
import random
from pathlib import Path
import sys

import numpy as np
import cv2
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

# ============================================================
# æŠŠ Awesome-U-Net åŠ åˆ° sys.path
# ============================================================

# train_unet.py: /root/autodl-tmp/tools/train_unet.py
THIS_DIR = Path(__file__).resolve().parent          # /root/autodl-tmp/tools
PROJECT_ROOT = THIS_DIR.parent                      # /root/autodl-tmp
AWESOME_UNET_ROOT = PROJECT_ROOT / "Unet" / "Awesome-U-Net"

sys.path.insert(0, str(AWESOME_UNET_ROOT))
print("âœ… Added to sys.path:", AWESOME_UNET_ROOT)

# ç°åœ¨å¯ä»¥ç›´æ¥ import models.XXX äº†
from models.unet import UNet
from models.attunet import AttU_Net
from models.unetpp import NestedUNet


# ============================================================
# Utils
# ============================================================

def set_seed(s=0):
    random.seed(s)
    np.random.seed(s)
    torch.manual_seed(s)
    torch.cuda.manual_seed_all(s)


def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)


def bce_dice_loss(logits, target):
    """
    logits: (B,1,H,W)
    target: (B,1,H,W) 0/1
    """
    bce = F.binary_cross_entropy_with_logits(logits, target.float())
    prob = torch.sigmoid(logits)
    smooth = 1.0
    inter = (prob * target).sum((2, 3))
    union = prob.sum((2, 3)) + target.sum((2, 3))
    dice = 1 - (2 * inter + smooth) / (union + smooth)
    return bce + dice.mean()


def compute_iou(pm, gm):
    """
    pm, gm: (H,W) 0/1
    """
    pm = pm.astype(bool)
    gm = gm.astype(bool)
    inter = (pm & gm).sum()
    uni = (pm | gm).sum()
    return float(inter) / float(uni + 1e-6)


IMG_EXTS = [".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff"]


# ============================================================
# Dataset: ä¸ SAM å¾®è°ƒä½¿ç”¨åŒä¸€å¥—æ•°æ®
# ============================================================

class SemanticSegDataset(Dataset):
    """
    åªåšè¯­ä¹‰åˆ†å‰² (å‰æ™¯/èƒŒæ™¯)ï¼Œä¸å†ç”¨ box prompt å’Œ SAM çš„ ResizeLongestSideï¼Œ
    ç›´æ¥ resize åˆ°å›ºå®šå¤§å° (img_size, img_size)ã€‚

    ROOT/
      images/{split}/xxx.jpg
      masks/{split}/xxx.png  # å•é€šé“ 0/255
    """

    def __init__(self, data_root, split, img_size=256):
        self.img_dir = Path(data_root) / "images" / split
        self.mask_dir = Path(data_root) / "masks" / split
        assert self.img_dir.exists(), f"{self.img_dir} ä¸å­˜åœ¨"
        assert self.mask_dir.exists(), f"{self.mask_dir} ä¸å­˜åœ¨"

        self.img_size = img_size
        self.samples = []

        for img_path in self.img_dir.iterdir():
            if not img_path.is_file():
                continue
            if img_path.suffix.lower() not in IMG_EXTS:
                continue
            stem = img_path.stem
            mask_path = self.mask_dir / f"{stem}.png"
            if mask_path.exists():
                self.samples.append({
                    "img": img_path,
                    "mask": mask_path,
                    "name": stem
                })

        print(f"[{split}] samples = {len(self.samples)} (UNet è¯­ä¹‰åˆ†å‰²)")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        p = self.samples[idx]

        # ---- è¯»å›¾åƒ ----
        bgr = cv2.imread(str(p["img"]), cv2.IMREAD_COLOR)
        if bgr is None:
            raise RuntimeError(f"è¯»å–å›¾åƒå¤±è´¥: {p['img']}")
        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)

        # ---- è¯» mask ----
        mask_img = cv2.imread(str(p["mask"]), cv2.IMREAD_GRAYSCALE)
        if mask_img is None:
            raise RuntimeError(f"è¯»å–maskå¤±è´¥: {p['mask']}")

        # ---- resize åˆ°ç»Ÿä¸€å¤§å° ----
        rgb = cv2.resize(rgb, (self.img_size, self.img_size), interpolation=cv2.INTER_LINEAR)
        mask = cv2.resize(mask_img, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)
        mask = (mask > 0).astype(np.float32)  # 0/1

        # ---- è½¬æˆ tensor ----
        rgb = rgb.astype(np.float32) / 255.0  # [0,1]
        rgb = rgb.transpose(2, 0, 1)          # (3,H,W)

        img_t = torch.from_numpy(rgb)         # (3,H,W)
        mask_t = torch.from_numpy(mask).unsqueeze(0)  # (1,H,W)

        return {
            "image": img_t,
            "mask": mask_t,
            "name": p["name"],
        }


# ============================================================
# æ„å»ºç½‘ç»œ
# ============================================================

def build_model(model_class: str, in_channels: int = 3, out_channels: int = 1):
    """
    model_class: å­—ç¬¦ä¸²ï¼Œä¾‹ï¼š
        "UNet" / "AttU_Net" / "NestedUNet"
    """

    name = model_class.lower()

    if name == "unet":
        # ä¼˜å…ˆç”¨ä½ç½®å‚æ•°ï¼Œé€‚é…å¤§å¤šæ•°å®ç°ï¼š(in_channels, out_channels) / (img_ch, output_ch) / (n_channels, n_classes)
        try:
            model = UNet(in_channels, out_channels)
        except TypeError:
            # å¦‚æœå®ç°é‡Œæ ¹æœ¬ä¸éœ€è¦è¿™ä¸¤ä¸ªå‚æ•°ï¼ˆå†™æ­»äº† 3->1ï¼‰ï¼Œå°±ç›´æ¥æ— å‚æ„é€ 
            model = UNet()

    elif name in ["attunet", "att_u_net", "attenunet"]:
        # Attention U-Netï¼Œä¸€èˆ¬ä¹Ÿæ˜¯ (img_ch, output_ch)
        try:
            model = AttU_Net(in_channels, out_channels)
        except TypeError:
            try:
                model = AttU_Net(img_ch=in_channels, output_ch=out_channels)
            except TypeError:
                model = AttU_Net()


    elif name in ["unet++", "unetpp", "nestedunet"]:

        # âœ… å¯¹åº”ä½ è´´å‡ºæ¥çš„ NestedUNet(num_classes, input_channels=3, deep_supervision=False)

        model = NestedUNet(

            num_classes=out_channels,  # ç±»åˆ«æ•°ï¼š1ï¼ˆå‰æ™¯/èƒŒæ™¯ï¼‰

            input_channels=in_channels,  # è¾“å…¥é€šé“ï¼š3

            deep_supervision=False

        )


    else:

        raise ValueError(f"æœªçŸ¥çš„ model_class: {model_class} (æ”¯æŒ: UNet / AttU_Net / UNet++)")

    return model

# ============================================================
# Evaluate
# ============================================================

@torch.no_grad()
def evaluate(model, loader, device, amp=True):
    """
    åœ¨éªŒè¯é›†ä¸Šè®¡ç®— Loss å’Œ mIoU
    """
    model.eval()
    tot_loss, tot_iou, cnt = 0.0, 0.0, 0

    for batch in loader:
        img = batch["image"].to(device)   # (B,3,H,W)
        gt = batch["mask"].to(device)     # (B,1,H,W)

        with torch.cuda.amp.autocast(enabled=amp):
            logits = model(img)           # (B,1,H,W)
            loss = bce_dice_loss(logits, gt)

        tot_loss += loss.item()

        prob = torch.sigmoid(logits)
        pred = (prob > 0.5).float()

        B = img.shape[0]
        for i in range(B):
            pm = pred[i, 0].detach().cpu().numpy()
            gm = gt[i, 0].detach().cpu().numpy()
            tot_iou += compute_iou(pm, gm)
            cnt += 1

    model.train()
    avg_loss = tot_loss / max(1, len(loader))
    miou = tot_iou / max(1, cnt)
    return avg_loss, miou


# ============================================================
# Train
# ============================================================

def train_unet(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("ä½¿ç”¨è®¾å¤‡:", device)

    set_seed(args.seed)

    # æƒé‡æ ¹ç›®å½•ï¼šunet_weights/{net_name}/
    weights_root = Path(args.weights_root)
    model_dir = weights_root / args.net.lower()
    ensure_dir(model_dir)
    print(f"æƒé‡ä¿å­˜ç›®å½•: {model_dir}")

    # ===== Dataset =====
    train_ds = SemanticSegDataset(args.data_root, "train", img_size=args.img_size)
    val_ds = SemanticSegDataset(args.data_root, "valid", img_size=args.img_size)

    train_loader = DataLoader(
        train_ds,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.workers,
        pin_memory=True,
        drop_last=True
    )

    val_loader = DataLoader(
        val_ds,
        batch_size=args.val_batch_size,
        shuffle=False,
        num_workers=args.workers,
        pin_memory=True
    )

    # ===== Model =====
    model = build_model(args.net).to(device)
    print(model.__class__.__name__)

    opt = torch.optim.AdamW(
        model.parameters(),
        lr=args.lr,
        weight_decay=args.weight_decay
    )

    scaler = torch.cuda.amp.GradScaler(enabled=args.amp)

    best_miou = 0.0

    # ============================================================
    #            Train Loop
    # ============================================================
    for epoch in range(args.epochs):
        total_loss = 0.0
        t0 = time.time()
        model.train()

        pbar = tqdm(train_loader, desc=f"[{args.net}] Epoch {epoch+1}/{args.epochs}")

        for batch in pbar:
            img = batch["image"].to(device)   # (B,3,H,W)
            gt = batch["mask"].to(device)     # (B,1,H,W)

            with torch.cuda.amp.autocast(enabled=args.amp):
                logits = model(img)           # (B,1,H,W)
                loss = bce_dice_loss(logits, gt)

            opt.zero_grad(set_to_none=True)
            scaler.scale(loss).backward()
            scaler.step(opt)
            scaler.update()

            total_loss += loss.item()
            pbar.set_postfix({"loss": f"{loss.item():.4f}"})

        train_loss = total_loss / len(train_loader)

        # ====== Validation ======
        val_loss, miou = evaluate(
            model,
            val_loader,
            device,
            amp=args.amp
        )

        print(f"Epoch {epoch+1}/{args.epochs} | "
              f"TrainLoss={train_loss:.4f} | ValLoss={val_loss:.4f} | mIoU={miou:.4f} | "
              f"Time={time.time()-t0:.1f}s")

        # ä¿å­˜å½“å‰ epoch æƒé‡
        ckpt = {
            "epoch": epoch + 1,
            "model": model.state_dict(),
            "optimizer": opt.state_dict(),
            "miou": miou,
        }
        torch.save(ckpt, str(model_dir / f"epoch{epoch+1:03d}.pth"))

        # ä¿å­˜ best æƒé‡
        if miou > best_miou:
            best_miou = miou
            ckpt["best_miou"] = best_miou
            torch.save(ckpt, str(model_dir / "best.pth"))
            print(f"ğŸ‰ New Best mIoU = {best_miou:.4f} -> å·²ä¿å­˜åˆ° {model_dir/'best.pth'}")

    print("è®­ç»ƒå®Œæˆï¼æœ€ä¼˜æ¨¡å‹ä¿å­˜åœ¨:", model_dir / "best.pth")


# ============================================================
# Main
# ============================================================

def parse_args():
    ap = argparse.ArgumentParser("UNet Family Training for Semantic Segmentation (Foreground/Background)")

    ap.add_argument("--data_root", default="/root/autodl-tmp/dataset_seg",
                    help="ä¸ SAM å¾®è°ƒæ—¶ç›¸åŒçš„æ•°æ®æ ¹ç›®å½•")
    ap.add_argument("--weights_root", default="/root/autodl-tmp/Unet/unet_weights",
                    help="æ‰€æœ‰ UNet æƒé‡çš„æ ¹ç›®å½•")
    ap.add_argument("--net", type=str, default="unet++",
                    help="é€‰æ‹©ç½‘ç»œç»“æ„: unet / attenunet / unet++")

    ap.add_argument("--img_size", type=int, default=256)
    ap.add_argument("--epochs", type=int, default=50)
    ap.add_argument("--batch_size", type=int, default=8)
    ap.add_argument("--val_batch_size", type=int, default=4)
    ap.add_argument("--workers", type=int, default=4)
    ap.add_argument("--lr", type=float, default=1e-4)
    ap.add_argument("--weight_decay", type=float, default=1e-4)
    ap.add_argument("--amp", action="store_true")
    ap.add_argument("--seed", type=int, default=42)

    return ap.parse_args()


if __name__ == "__main__":
    args = parse_args()
    print("=" * 60)
    print("UNet å®¶æ—å‰æ™¯/èƒŒæ™¯è¯­ä¹‰åˆ†å‰²è®­ç»ƒ")
    print("=" * 60)
    for k, v in vars(args).items():
        print(f"{k}: {v}")
    print("=" * 60)
    train_unet(args)
